{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfayf7NSMr-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "481d89ba-a90a-4614-bcc1-c771e46e35f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-04 14:31:16--  https://ml-hiring.fringecore.sh/capture_the_scene/video.mp4\n",
            "Resolving ml-hiring.fringecore.sh (ml-hiring.fringecore.sh)... 104.21.75.216, 172.67.182.61, 2606:4700:3037::ac43:b63d, ...\n",
            "Connecting to ml-hiring.fringecore.sh (ml-hiring.fringecore.sh)|104.21.75.216|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3700355 (3.5M) [video/mp4]\n",
            "Saving to: ‘video/video.mp4.3’\n",
            "\n",
            "video.mp4.3         100%[===================>]   3.53M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-07-04 14:31:17 (39.8 MB/s) - ‘video/video.mp4.3’ saved [3700355/3700355]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Get Video\n",
        "!wget -P video/ \"https://ml-hiring.fringecore.sh/capture_the_scene/video.mp4\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to Implement"
      ],
      "metadata": {
        "id": "Xr8XVaQcS6of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The EVL pano code gets terminated while calling process_video_for_pano(video_file_path)\n",
        "# For the access of insufficient RAM\n",
        "# Although frames limit is 30 and size is  320x180\n",
        "# Run this in premium Colab or in local machine for the output\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def process_video_for_pano(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video {video_path}\")\n",
        "        return None\n",
        "\n",
        "    # Get video properties\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    print(f\"Video properties: {width}x{height}, {fps} FPS, {total_frames} frames\")\n",
        "\n",
        "    # Sampling interval\n",
        "    frame_interval = max(1, fps // 2)  # Sample 2 frames per second\n",
        "\n",
        "    MAX_FRAMES = 30\n",
        "    RESIZE_WIDTH = 320\n",
        "\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "\n",
        "    print(\"Extracting frames...\")\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret or len(frames) >= MAX_FRAMES:\n",
        "            break\n",
        "\n",
        "        if frame_count % frame_interval == 0:\n",
        "            frame = cv2.resize(frame, (RESIZE_WIDTH, int(frame.shape[0] * RESIZE_WIDTH / frame.shape[1])))\n",
        "            frames.append(frame)\n",
        "            if len(frames) % 10 == 0:\n",
        "                print(f\"Extracted {len(frames)} frames...\")\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if len(frames) < 2:\n",
        "        print(\"Error: Not enough frames extracted\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Total frames extracted: {len(frames)}\")\n",
        "\n",
        "    # Initialize panorama\n",
        "    panorama = frames[0].copy()\n",
        "\n",
        "    # Feature matcher\n",
        "    sift = cv2.SIFT_create()\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "    search_params = dict(checks=50)\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    print(\"Creating panorama...\")\n",
        "    successful_stitches = 0\n",
        "\n",
        "    for i in range(1, len(frames)):\n",
        "        current_frame = frames[i]\n",
        "\n",
        "        try:\n",
        "            kp1, des1 = sift.detectAndCompute(panorama, None)\n",
        "            kp2, des2 = sift.detectAndCompute(current_frame, None)\n",
        "\n",
        "            if des1 is None or des2 is None:\n",
        "                continue\n",
        "\n",
        "            matches = flann.knnMatch(des1, des2, k=2)\n",
        "\n",
        "            good_matches = []\n",
        "            for match_pair in matches:\n",
        "                if len(match_pair) == 2:\n",
        "                    m, n = match_pair\n",
        "                    if m.distance < 0.7 * n.distance:\n",
        "                        good_matches.append(m)\n",
        "\n",
        "            if len(good_matches) < 10:\n",
        "                continue\n",
        "\n",
        "            src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "\n",
        "            H, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
        "            if H is None:\n",
        "                continue\n",
        "\n",
        "            h1, w1 = panorama.shape[:2]\n",
        "            h2, w2 = current_frame.shape[:2]\n",
        "\n",
        "            corners = np.float32([[0, 0], [w2, 0], [w2, h2], [0, h2]]).reshape(-1, 1, 2)\n",
        "            transformed_corners = cv2.perspectiveTransform(corners, H)\n",
        "\n",
        "            all_corners = np.concatenate([[[0, 0], [w1, 0], [w1, h1], [0, h1]], transformed_corners.reshape(-1, 2)])\n",
        "            x_min, y_min = np.int32(all_corners.min(axis=0).ravel())\n",
        "            x_max, y_max = np.int32(all_corners.max(axis=0).ravel())\n",
        "\n",
        "            translation = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]], dtype=np.float32)\n",
        "\n",
        "            warped = cv2.warpPerspective(current_frame, translation @ H, (x_max - x_min, y_max - y_min))\n",
        "            warped_panorama = cv2.warpPerspective(panorama, translation, (x_max - x_min, y_max - y_min))\n",
        "\n",
        "            mask = (warped > 0).astype(np.uint8)\n",
        "            result = np.where(mask, warped, warped_panorama)\n",
        "\n",
        "            panorama = result\n",
        "            successful_stitches += 1\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Processed {i}/{len(frames)} frames, successful stitches: {successful_stitches}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing frame {i}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"Panorama creation completed. Total successful stitches: {successful_stitches}\")\n",
        "\n",
        "    output_dir = \"video\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    path_to_pano = os.path.join(output_dir, \"panorama.jpg\")\n",
        "    cv2.imwrite(path_to_pano, panorama)\n",
        "\n",
        "    plt.figure(figsize=(20, 6))\n",
        "    panorama_rgb = cv2.cvtColor(panorama, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(panorama_rgb)\n",
        "    plt.title(\"Video Panorama\")\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Panorama saved to: {path_to_pano}\")\n",
        "    print(f\"Panorama dimensions: {panorama.shape[1]}x{panorama.shape[0]}\")\n",
        "\n",
        "\n",
        "  # path_to_pano= None\n",
        "    return path_to_pano\n"
      ],
      "metadata": {
        "id": "EAuhKIj-SvgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval"
      ],
      "metadata": {
        "id": "314uyzUxSbhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Get Pano\n",
        "\n",
        "video_file_path = '/content/video/video.mp4'\n",
        "process_video_for_pano(video_file_path)\n"
      ],
      "metadata": {
        "id": "OYLJ9ymBP6kR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93fbe0c6-b269-4fb5-8ecc-4077bde265e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video properties: 720x1280, 30 FPS, 255 frames\n",
            "Extracting frames...\n",
            "Extracted 10 frames...\n",
            "Total frames extracted: 17\n",
            "Creating panorama...\n",
            "Processed 10/17 frames, successful stitches: 10\n"
          ]
        }
      ]
    }
  ]
}